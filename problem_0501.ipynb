{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.2 64-bit"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "problem_0501.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "fd88d7af6e94c6929b65b5dc552f91130e2e10e9038db61f82cd7f9c6aff4407"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Quiz #0501"
      ],
      "metadata": {
        "id": "rjgrimodz8si"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### \"Logistic Regression and Gradient Descent Algorithm\""
      ],
      "metadata": {
        "id": "jKWQCplWz8sm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Answer the following questions by providing Python code:\n",
        "#### Objectives:\n",
        "- Code a logistic regression class using only the NumPy library.\n",
        "- Implement in Python the Sigmoid function.\n",
        "- Implement in Python the Gradient of the logarithmic likelihood.\n",
        "- Implement in Python the Gradient Descent Algorithm."
      ],
      "metadata": {
        "id": "ii_vxXjRz8sp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from sklearn.datasets import load_breast_cancer\r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "outputs": [],
      "metadata": {
        "id": "qPXzVLLez8ss"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Read in data:"
      ],
      "metadata": {
        "id": "NfGrSwGhz8sv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "source": [
        "# Load data.\r\n",
        "data = load_breast_cancer()\r\n",
        "# Explanatory variables.\r\n",
        "X = data['data']\r\n",
        "# Relabel such that 0 = 'benign' and 1 = malignant.\r\n",
        "Y = 1 - data['target']"
      ],
      "outputs": [],
      "metadata": {
        "id": "5v7cO1Jez8sv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "source": [
        "# Split the dataset into training and testing.\r\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.4, random_state=1234)"
      ],
      "outputs": [],
      "metadata": {
        "id": "RfwOovCoz8sw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1). Define the 'sigmoid' and 'gradient' functions to produce the output shown below:"
      ],
      "metadata": {
        "id": "18dR-OLBz8sy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "source": [
        "def sigmoid(x):\r\n",
        "       return 1 / (1 + np.exp(-x))\r\n",
        "\r\n",
        "def gradient(X, Y, beta):\r\n",
        "       return np.dot(X.T, sigmoid(np.dot(X, beta)) - Y)"
      ],
      "outputs": [],
      "metadata": {
        "id": "yPOYE1H2z8sz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2). Define the 'LogisticRegression' class to produce the output shown below:"
      ],
      "metadata": {
        "id": "fW8tGbtKz8s3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "source": [
        "class LogisticRegression:\r\n",
        "    def __init__(self, learn_rate):\r\n",
        "        self.rate = learn_rate\r\n",
        "        self.n_nodes = None\r\n",
        "        self.beta = None\r\n",
        "        \r\n",
        "    def train(self, input_X, input_Y, n_epochs):\r\n",
        "        self.n_nodes = input_X.shape[1]\r\n",
        "        self.beta = np.zeros(self.n_nodes)\r\n",
        "        for _ in range(n_epochs):\r\n",
        "            self.beta -= self.rate * gradient(input_X, input_Y, self.beta)\r\n",
        "\r\n",
        "    \r\n",
        "    def query(self, input_X, cutoff=0.5):\r\n",
        "        return np.where(sigmoid(np.dot(input_X, self.beta)) > cutoff, 1, 0)\r\n",
        "             \r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "ZnWTClEYz8s4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sample run:"
      ],
      "metadata": {
        "id": "Q4LW6q4tz8s5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "source": [
        "# Hyperparameter for the learner.\r\n",
        "learning_rate = 0.001"
      ],
      "outputs": [],
      "metadata": {
        "id": "LF-BtAahz8s6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "source": [
        "# Train and predict.\r\n",
        "LR = LogisticRegression(learning_rate)\r\n",
        "LR.train(X_train, Y_train, 2000)\r\n",
        "Y_pred = LR.query(X_test,cutoff=0.5)"
      ],
      "outputs": [],
      "metadata": {
        "id": "qJKt4sffz8s7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "source": [
        "# Display the accuracy.\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "\r\n",
        "accuracy = accuracy_score(Y_test, Y_pred) \r\n",
        "\r\n",
        "print('Accuracy : {}'.format(np.round(accuracy,3)))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 0.912\n"
          ]
        }
      ],
      "metadata": {}
    }
  ]
}